# Default configuration for LLM Graph Reasoning Framework

# Model configuration
models:
  llama_openrouter:
    name: "meta-llama/llama-3.3-70b-instruct:free"
    type: "openrouter"
    base_url: "https://openrouter.ai/api/v1"
    temperature: 0.0
    max_tokens: 8192
    # API key should be set via environment variable: OPENROUTER_API_KEY
    # See .env.example for setup instructions
  
  llama:
    name: "llama3.1:8b-instruct"
    type: "ollama"
    base_url: "http://localhost:11434"
    temperature: 0.0
    max_tokens: 8192
    
  deepseek:
    name: "deepseek-r1:8b"
    type: "ollama"
    base_url: "http://localhost:11434"
    temperature: 0.0
    max_tokens: 8192
    
  gpt4o:
    name: "gpt-4o"
    type: "openai"
    temperature: 0.0
    max_tokens: 8192
    # API key should be set via environment variable: OPENAI_API_KEY

# Orchestrator configuration
orchestrator:
  max_iterations: 3  # Maximum reject-and-repair cycles
  timeout: 300  # Timeout in seconds per execution
  enable_logging: true
  enable_metrics: true

# Parser configuration
parser:
  template_type: "graphnl"
  retry_on_failure: true
  max_retries: 3

# Chooser configuration
chooser:
  confidence_threshold: 0.7
  use_few_shot: true
  few_shot_examples: 5

# Verifier configuration
verifier:
  strict_mode: true
  verify_structure: true
  verify_solution: true
  generate_feedback: true

# Algorithm configuration
algorithms:
  timeout: 30  # Timeout for individual algorithm execution
  
# Benchmark configuration
benchmarks:
  nlgraph_path: "data/nlgraph"
  graphinstruct_path: "data/graphinstruct"
  output_path: "results"
  
# Logging configuration
logging:
  level: "INFO"
  file: "logs/llm_graph.log"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {module}:{function}:{line} | {message}"

# TODO [CONFIG-001]: Add experiment-specific configurations
# TODO [CONFIG-002]: Add model-specific hyperparameters
# TODO [CONFIG-003]: Add benchmark filtering options
